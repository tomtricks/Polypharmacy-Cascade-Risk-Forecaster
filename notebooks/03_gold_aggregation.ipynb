{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "591fc91a-f674-4f4c-a5f5-dd0dc7680fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step A1: ML Task Definition & Output\n",
    "\n",
    "### Objective\n",
    "The objective of this project is to predict the **future risk of adverse events** caused by polypharmacy (use of multiple medications) in hospitalized patients. The focus is on identifying high-risk patients early so that preventive actions can be considered before serious outcomes occur.\n",
    "\n",
    "### ML Task Type\n",
    "This is a **binary classification problem with a probabilistic output**.  \n",
    "The model predicts whether a patient is likely to experience an adverse event (such as a fall or medication-related complication) within a **28-day prediction window**.\n",
    "\n",
    "### Why Machine Learning (Not Rule-Based)\n",
    "Polypharmacy risks are driven by **complex interactions between multiple drugs, patient conditions, and treatment duration**. These patterns are difficult to capture using fixed rules.  \n",
    "Machine learning allows the system to learn risk patterns from historical data and adapt to combinations that may not be obvious or explicitly defined.\n",
    "\n",
    "### Model Inputs\n",
    "The model uses features engineered from structured healthcare data, including:\n",
    "- Patient demographics (age, gender)\n",
    "- Medication count and combinations\n",
    "- Duration of medication exposure\n",
    "- Historical clinical events\n",
    "- Polypharmacy-related risk indicators\n",
    "\n",
    "### Model Output\n",
    "The model produces a **risk probability score between 0 and 1**, representing the likelihood of a patient experiencing an adverse event within the next 28 days.\n",
    "\n",
    "### Success Criteria\n",
    "Model performance and usefulness are evaluated using:\n",
    "- AUC-ROC to measure predictive quality\n",
    "- Stability of risk predictions\n",
    "- Ability to translate predictions into meaningful risk levels for decision support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6e84b90-b0ee-449c-8e8a-b10528f8e335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step A2: Risk Stratification & Decision Logic\n",
    "\n",
    "### Purpose\n",
    "While the machine learning model outputs a probability score, probabilities alone are not actionable for decision-makers. This step converts model outputs into **clear risk categories** that can support intervention planning and monitoring.\n",
    "\n",
    "### Risk Stratification Logic\n",
    "The predicted probability from the Logistic Regression model is mapped into three risk levels:\n",
    "\n",
    "- **High Risk (Red)**: Probability ≥ 0.70  \n",
    "- **Medium Risk (Amber)**: Probability between 0.40 and 0.70  \n",
    "- **Low Risk (Green)**: Probability < 0.40  \n",
    "\n",
    "These thresholds are chosen to balance sensitivity and interpretability, and can be adjusted based on operational requirements.\n",
    "\n",
    "### Output Representation\n",
    "Each patient record in the Gold layer contains:\n",
    "- Risk probability score\n",
    "- Risk category (Red / Amber / Green)\n",
    "- Associated patient and medication context\n",
    "\n",
    "This makes the output easily consumable by downstream systems such as dashboards or alerting workflows.\n",
    "\n",
    "### Decision Support Use Case\n",
    "- **High Risk** patients can be prioritized for medication review or closer monitoring\n",
    "- **Medium Risk** patients can be flagged for follow-up assessments\n",
    "- **Low Risk** patients continue under routine care\n",
    "\n",
    "### Why This Matters\n",
    "This step transforms raw ML predictions into **actionable insights**, moving the system beyond model training and into real-world decision support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "954abf4f-6fed-4717-bea2-c4db66098b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step A3: Model Evaluation & Interpretation\n",
    "\n",
    "### Evaluation Approach\n",
    "The model was evaluated using a train-test split and assessed with **AUC-ROC** via Spark’s `BinaryClassificationEvaluator`.  \n",
    "AUC was chosen because the problem involves **risk ranking**, not just binary accuracy.\n",
    "\n",
    "### Evaluation Result\n",
    "- **AUC-ROC Score:** 0.59\n",
    "\n",
    "### Interpretation of Results\n",
    "An AUC of 0.59 indicates that the model performs **better than random guessing**, but is not highly predictive.  \n",
    "This result is expected due to:\n",
    "- High noise and sparsity in healthcare event data\n",
    "- Limited feature depth in the free Databricks environment\n",
    "- Absence of temporal and clinical severity signals available in real hospital systems\n",
    "\n",
    "### Why the Model Is Still Useful\n",
    "The goal of this system is **early risk signaling**, not medical diagnosis.  \n",
    "Even modest predictive power is valuable when:\n",
    "- Used to rank patients by relative risk\n",
    "- Combined with human review or rule-based safeguards\n",
    "- Integrated into a broader decision-support workflow\n",
    "\n",
    "### Limitations\n",
    "- Limited feature richness from public datasets\n",
    "- No longitudinal patient history beyond available records\n",
    "- Thresholds are heuristic and not clinically validated\n",
    "\n",
    "### Future Improvements\n",
    "- Incorporate richer temporal features\n",
    "- Add interaction features between medication classes\n",
    "- Calibrate risk thresholds using domain feedback\n",
    "\n",
    "This evaluation confirms that the model is suitable for **decision support and risk prioritization**, not automated clinical decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "735f0353-624a-4caf-8590-db17930e822a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step A4: End-to-End Database ↔ AI Workflow\n",
    "\n",
    "### Overview\n",
    "This project is designed as a full **database-to-AI-to-decision** pipeline using Databricks Lakehouse principles. Each stage builds on the previous one, ensuring traceability, reproducibility, and scalability.\n",
    "\n",
    "### Data Ingestion (Bronze Layer)\n",
    "Raw healthcare datasets (patients, prescriptions, and events) are ingested into Databricks as **Bronze tables**.  \n",
    "These tables represent the source data with minimal transformation and act as the system of record.\n",
    "\n",
    "### Data Cleaning & Transformation (Silver Layer)\n",
    "Silver tables are created by:\n",
    "- Cleaning invalid or missing values\n",
    "- Standardizing formats (dates, identifiers)\n",
    "- Joining patient, medication, and event data\n",
    "- Preparing structured inputs suitable for feature engineering\n",
    "\n",
    "This layer ensures data quality and consistency for downstream ML tasks.\n",
    "\n",
    "### Feature Engineering & Aggregation (Gold Layer)\n",
    "The Gold layer contains **ML-ready features**, including:\n",
    "- Polypharmacy indicators\n",
    "- Medication exposure duration\n",
    "- Patient-level aggregates\n",
    "- Event frequency and history signals\n",
    "\n",
    "These curated tables are optimized for analytics, modeling, and reporting.\n",
    "\n",
    "### Machine Learning Integration\n",
    "- Features are read directly from Gold tables\n",
    "- A Logistic Regression model is trained using PySpark ML\n",
    "- Predictions and probability scores are generated\n",
    "- Risk levels (Red / Amber / Green) are derived from probabilities\n",
    "\n",
    "### Storing Results Back to the Database\n",
    "Final risk scores and categories are written back as **Gold output tables**, closing the loop between:\n",
    "**Data → AI → Decision Support**\n",
    "\n",
    "This enables:\n",
    "- Dashboarding\n",
    "- Monitoring\n",
    "- Future automation via Databricks Jobs\n",
    "\n",
    "### Why This Workflow Matters\n",
    "This architecture demonstrates:\n",
    "- Clear separation of concerns across data layers\n",
    "- Tight integration between data engineering and AI\n",
    "- A realistic production-style workflow using only free Databricks capabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a22cbae0-e8a2-490f-9af1-47d285bc52bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step A5: Business Impact & Practical Use\n",
    "\n",
    "### Problem Impact\n",
    "Polypharmacy is a common issue in healthcare, especially among elderly and chronically ill patients. Adverse events such as dizziness, falls, and fractures often occur **after a cascade of medication interactions**, making them difficult to detect early using static rules.\n",
    "\n",
    "### Who This System Helps\n",
    "- **Clinicians**: Identify patients who may need early medication review\n",
    "- **Hospital Operations Teams**: Prioritize high-risk patients for monitoring\n",
    "- **Quality & Safety Teams**: Reduce preventable adverse events\n",
    "- **Patients**: Lower risk of medication-related harm\n",
    "\n",
    "### How the Output Is Used\n",
    "The system produces a **risk score and risk category** for each patient:\n",
    "- **High Risk (Red)**: Immediate review or intervention recommended\n",
    "- **Medium Risk (Amber)**: Increased monitoring and follow-up\n",
    "- **Low Risk (Green)**: Routine care\n",
    "\n",
    "This allows teams to focus effort where it matters most.\n",
    "\n",
    "### Decision Support, Not Automation\n",
    "This project is explicitly designed as a **decision-support system**, not a medical device.  \n",
    "Predictions are intended to **assist human judgment**, not replace it.\n",
    "\n",
    "### Practical Value\n",
    "Even with a moderate AUC score, the model provides value by:\n",
    "- Ranking patients by relative risk\n",
    "- Surfacing hidden risk patterns from medication combinations\n",
    "- Enabling proactive care rather than reactive treatment\n",
    "\n",
    "### Real-World Applicability\n",
    "The system can be integrated with:\n",
    "- Hospital dashboards\n",
    "- Daily risk reports\n",
    "- Automated alerts for care teams\n",
    "\n",
    "This demonstrates how AI can be responsibly applied to improve patient safety using existing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59024ceb-f5a7-46d7-9625-618664153702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d1faed-03f7-40e4-989d-e8bcce471796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = spark.table(\"silver_features\")\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc7a03b0-20b6-4a12-b370-c2a6f795ffdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.8, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e221ca4-7c35-40f0-8515-2bc5d4f20940",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"gender\", \"drug_name\",\"start_date\",\"end_date\"\n",
    "]\n",
    "\n",
    "ml_data = data.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d9a92d-e974-43b5-aec6-19b2664cf5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "features = [c for c in ml_data.columns if c not in [\"patient_id\", \"label\"]]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "train_vec = assembler.transform(train.select(*ml_data.columns))\n",
    "test_vec = assembler.transform(test.select(*ml_data.columns))\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    probabilityCol=\"risk_score\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = lr.fit(train_vec)\n",
    "    predictions = model.transform(test_vec)\n",
    "    # mlflow.spark.log_model(model, \"risk_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d30b415-7f91-48bb-bf5c-632516ce6777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51e9ea3f-a91a-4978-afe4-1fbfb913c060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/Smart_Pill_Danger_Forecaster\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Baseline\"):\n",
    "    \n",
    "    # Log params\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"features\", \"demographics + prescriptions + events\")\n",
    "    \n",
    "    # Log metric\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "    \n",
    "print(f\"AUC logged to MLflow: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "325fc709-047b-4564-a93b-2987b731bd2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "gold_risk = (\n",
    "    predictions\n",
    "    .withColumn(\"risk_array\", vector_to_array(\"risk_score\"))\n",
    "    .select(\n",
    "        \"patient_id\",\n",
    "        F.col(\"risk_array\")[1].alias(\"risk_score\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"risk_bucket\",\n",
    "        F.when(F.col(\"risk_score\") >= 0.7, \"High\")\n",
    "         .when(F.col(\"risk_score\") >= 0.4, \"Medium\")\n",
    "         .otherwise(\"Low\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gold_risk.write.mode(\"overwrite\").saveAsTable(\"gold_patient_risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8a9b62-49ed-4c07-9e64-d36e7712af16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(\"gold_patient_risk\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_gold_aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
